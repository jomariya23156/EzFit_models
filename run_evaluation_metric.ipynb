{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e4ed93-543c-4a81-a88e-c51efce3c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 16:40:42.153765: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "\n",
    "from collections import deque, Counter\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e3ca6-86d4-47a0-8589-17caa693b56b",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0ebca-4f3c-476f-b074-31b6d127eb37",
   "metadata": {},
   "source": [
    "from: https://www.mdpi.com/2414-4088/5/9/55\n",
    "section 4.3.2 repetition counting  \n",
    "*OBO is\n",
    "above 99%, denoting that almost all the test samples are within +-1 of groundtruth.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35047136-19e4-47be-ae76-6b5386fdda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OBO(y_pred: int, y_true: int) -> int:\n",
    "    return int(y_pred >= y_true-1 and y_pred <= y_true+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583266da-3281-42c3-aa1e-d1fe2ef2cd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OBO(9,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52364383-3a9f-4567-8ac4-1c3fe55982b0",
   "metadata": {},
   "source": [
    "## Custom Objects for ViViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cda96e1-0aff-45b9-a657-347468df833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2107262c-8b56-4e61-9780-75591e3fe3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "        \n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fb3854c-8c7a-4ab9-83ea-db197ad49826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding='VALID'\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "        \n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'patch_size': self.patch_size,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c235ff-3849-4a48-a078-a6b6a87a199b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bc77399-dbc0-4dd4-8823-fddbfb6cd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTING_ORDER = {\n",
    "    'pushup': {\n",
    "        'cur_class': 'pushup-up',\n",
    "        'prev_class': 'pushup-down'\n",
    "    },\n",
    "    'squat': {\n",
    "        'cur_class': 'squat-up',\n",
    "        'prev_class': 'squat-down'\n",
    "    },\n",
    "    'jumping-jack': {\n",
    "        'cur_class': 'jumping-jack-down',\n",
    "        'prev_class': 'jumping-jack-up'\n",
    "    },\n",
    "    'leg-raise': {\n",
    "        'cur_class': 'leg-raise-down',\n",
    "        'prev_class': 'leg-raise-up'\n",
    "    },\n",
    "    'half-burpee': {\n",
    "        'cur_class': 'half-burpee-out',\n",
    "        'prev_class': 'half-burpee-in'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5629033c-43fe-4024-9f0e-ad92c5d9b629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model and counting\n",
    "# EXERCISE = 'pushup'\n",
    "# CUR_CLASS = 'up'\n",
    "# PREV_CLASS = 'down'\n",
    "\n",
    "MODEL_TYPE = 'image_single'\n",
    "POST = 'hard_vote'\n",
    "WINDOW_SIZE = 15 # window size for hard voting\n",
    "BEST = False\n",
    "ROUND_MAPPING = {\n",
    "    'pushup': 6,\n",
    "    'squat': 4,\n",
    "    'jumping-jack': 3,\n",
    "    'leg-raise': 2,\n",
    "    'half-burpee': 1,\n",
    "}\n",
    "SEQ_LEN = 8\n",
    "\n",
    "# input videos\n",
    "DS_BASE_DIR = 'evaluation_videos/EzFit_dataset'\n",
    "VID_DIR = os.path.join(DS_BASE_DIR, 'videos')\n",
    "OUT_DIR = os.path.join(DS_BASE_DIR, 'outputs')\n",
    "GT_CSV = os.path.join(DS_BASE_DIR, 'labels/label_v1.csv')\n",
    "\n",
    "if MODEL_TYPE == 'ViViT':\n",
    "    custom_objects = {\"TubeletEmbedding\": TubeletEmbedding, \n",
    "                      \"PositionalEncoder\": PositionalEncoder}\n",
    "else:\n",
    "    custom_objects = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25788a28-cb13-4acd-b928-4d2bf1a4333e",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c4caef01-3f6b-494f-8aca-c18b2abb7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a244e71e-cca1-4c36-87c6-b2e643760db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>rep</th>\n",
       "      <th>exercise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>half-burpee_1_1.mp4</td>\n",
       "      <td>11</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-burpee_1_2.mp4</td>\n",
       "      <td>9</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-burpee_2_1.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>half-burpee_2_2.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-burpee_2_3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>squat_3_1.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>squat_3_2.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>squat_3_3.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>squat_3_4.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>squat_3_5.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name  rep     exercise\n",
       "0   half-burpee_1_1.mp4   11  half-burpee\n",
       "1   half-burpee_1_2.mp4    9  half-burpee\n",
       "2   half-burpee_2_1.mp4    3  half-burpee\n",
       "3   half-burpee_2_2.mp4    4  half-burpee\n",
       "4   half-burpee_2_3.mp4    3  half-burpee\n",
       "..                  ...  ...          ...\n",
       "63        squat_3_1.mp4    8        squat\n",
       "64        squat_3_2.mp4    6        squat\n",
       "65        squat_3_3.mp4    7        squat\n",
       "66        squat_3_4.mp4    5        squat\n",
       "67        squat_3_5.mp4    5        squat\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(GT_CSV)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08416f41-758b-4ee5-be03-ddacc7cae20f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half-burpee_1_1.mp4: 0 from 11\n",
      "half-burpee_1_2.mp4: 0 from 9\n",
      "half-burpee_2_1.mp4: 0 from 3\n",
      "half-burpee_2_2.mp4: 0 from 4\n",
      "half-burpee_2_3.mp4: 0 from 3\n",
      "half-burpee_2_4.mp4: 0 from 3\n",
      "half-burpee_2_5.mp4: 0 from 4\n",
      "half-burpee_2_6.mp4: 0 from 2\n",
      "half-burpee_3_1.mp4: 0 from 4\n",
      "half-burpee_3_2.mp4: 0 from 4\n",
      "half-burpee_3_3.mp4: 0 from 4\n",
      "half-burpee_3_4.mp4: 0 from 3\n",
      "half-burpee_3_5.mp4: 0 from 4\n",
      "jumping-jack_1_1.mp4: 0 from 11\n",
      "jumping-jack_1_2.mp4: 0 from 11\n",
      "jumping-jack_1_3.mp4: 0 from 12\n",
      "jumping-jack_2_1.mp4: 0 from 10\n",
      "jumping-jack_2_2.mp4: 0 from 10\n",
      "jumping-jack_2_3.mp4: 0 from 7\n",
      "jumping-jack_2_4.mp4: 0 from 9\n",
      "jumping-jack_3_1.mp4: 0 from 8\n",
      "jumping-jack_3_2.mp4: 0 from 7\n",
      "jumping-jack_3_3.mp4: 0 from 7\n",
      "jumping-jack_3_4.mp4: 0 from 7\n",
      "jumping-jack_3_5.mp4: 0 from 7\n",
      "jumping-jack_3_6.mp4: 0 from 4\n",
      "jumping-jack_3_7.mp4: 0 from 7\n",
      "jumping-jack_extra_1.mp4: 0 from 9\n",
      "jumping-jack_extra_2.mp4: 0 from 6\n",
      "leg-raise_1_1.mp4: 0 from 9\n",
      "leg-raise_1_2.mp4: 0 from 8\n",
      "leg-raise_2_1.mp4: 0 from 4\n",
      "leg-raise_2_2.mp4: 0 from 3\n",
      "leg-raise_2_3.mp4: 0 from 3\n",
      "leg-raise_2_4.mp4: 0 from 3\n",
      "leg-raise_2_5.mp4: 0 from 3\n",
      "leg-raise_3_1.mp4: 0 from 6\n",
      "leg-raise_3_2.mp4: 0 from 5\n",
      "leg-raise_3_3.mp4: 0 from 5\n",
      "leg-raise_3_4.mp4: 0 from 4\n",
      "leg-raise_extra_1.mp4: 0 from 5\n",
      "leg-raise_extra_2.mp4: 0 from 6\n",
      "leg-raise_extra_3.mp4: 0 from 6\n",
      "pushup_1_1.mp4: 0 from 17\n",
      "pushup_1_2.mp4: 0 from 17\n",
      "pushup_2_1.mp4: 2 from 7\n",
      "pushup_2_2.mp4: 0 from 5\n",
      "pushup_2_3.mp4: 2 from 5\n",
      "pushup_3_1.mp4: 0 from 7\n",
      "pushup_3_2.mp4: 0 from 6\n",
      "pushup_3_3.mp4: 0 from 5\n",
      "pushup_3_4.mp4: 0 from 5\n",
      "pushup_3_5.mp4: 0 from 4\n",
      "pushup_3_6.mp4: 0 from 3\n",
      "pushup_3_7.mp4: 2 from 3\n",
      "pushup_3_8.mp4: 0 from 3\n",
      "squat_1_1.mp4: 6 from 6\n",
      "squat_1_2.mp4: 5 from 5\n",
      "squat_2_1.mp4: 6 from 6\n",
      "squat_2_2.mp4: 5 from 5\n",
      "squat_2_3.mp4: 4 from 4\n",
      "squat_2_4.mp4: 2 from 4\n",
      "squat_2_5.mp4: 1 from 5\n",
      "squat_3_1.mp4: 0 from 8\n",
      "squat_3_2.mp4: 0 from 6\n",
      "squat_3_3.mp4: 0 from 7\n",
      "squat_3_4.mp4: 0 from 5\n",
      "squat_3_5.mp4: 0 from 5\n"
     ]
    }
   ],
   "source": [
    "cur_ex = None\n",
    "prev_ex = None\n",
    "all_obos = []\n",
    "all_reps = []\n",
    "for idx, row in df.iterrows():\n",
    "    # 0 -> file_name, 1 -> rep, so on...\n",
    "    file_name = row[0]\n",
    "    rep_gt = row[1]\n",
    "    exercise = row[2]\n",
    "    cur_ex = exercise\n",
    "    rep_count = 0\n",
    "    # if exercise changes, reload model and le to corresponded exercise\n",
    "    if cur_ex != prev_ex:\n",
    "        if BEST:\n",
    "            model_path = f'final_models/h5/{exercise}_{MODEL_TYPE}.h5'\n",
    "            le_path = f'final_models/le/{exercise}_{MODEL_TYPE}_le.pickle'\n",
    "        else:\n",
    "            model_path = f'saved_models/round_{ROUND_MAPPING[exercise]}/{exercise}/{exercise}_{MODEL_TYPE}.h5'\n",
    "            if MODEL_TYPE == 'kps_single':\n",
    "                le_path = f'saved_pickles/round_{ROUND_MAPPING[exercise]}/{exercise}/{exercise}_{MODEL_TYPE}_lb.pickle'\n",
    "            else:\n",
    "                le_path = f'saved_pickles/round_{ROUND_MAPPING[exercise]}/{exercise}/{exercise}_{MODEL_TYPE}_le.pickle'\n",
    "        # load model and le\n",
    "        loaded_model = load_model(model_path, custom_objects=custom_objects)\n",
    "        with open(le_path, 'rb') as file:\n",
    "            loaded_le = pickle.load(file)\n",
    "    \n",
    "    # start loading video and count\n",
    "    if 'kps' in MODEL_TYPE: # kps-based models\n",
    "        kps_seq = deque(maxlen=SEQ_LEN)\n",
    "        current_stage = None\n",
    "        previous_stage = None\n",
    "        if POST == 'hard_vote':\n",
    "            preds_window = deque(maxlen=WINDOW_SIZE)\n",
    "        cap = cv2.VideoCapture(os.path.join(VID_DIR, exercise, file_name))\n",
    "        with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "            while cap.isOpened():\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(image)\n",
    "\n",
    "                # append face&body coordinates for each frame to the csv file to create dataset to train the model\n",
    "                try:\n",
    "                    # extract pose\n",
    "                    pose_coor = results.pose_landmarks.landmark\n",
    "                    pose_row = np.array([[landmark.x, landmark.y, landmark.visibility] for landmark in pose_coor]).flatten()\n",
    "                    # append new coor to the sequence array\n",
    "                    \n",
    "                    if MODEL_TYPE == 'kps_single':\n",
    "                        y_hat = loaded_model.predict(tf.expand_dims(pose_row, axis=0))[0]\n",
    "                        y_idx = np.argmax(y_hat)\n",
    "                        if POST == 'hard_vote':\n",
    "                            # do hard voting\n",
    "                            preds_window.append(y_idx)\n",
    "                            pred_count = Counter(preds_window)\n",
    "                            # most_common return .items() format\n",
    "                            # ex. [(0,5), (1,3)]\n",
    "                            voted_pred = pred_count.most_common(1)[0][0]\n",
    "                            class_name = loaded_le.classes_[voted_pred]\n",
    "                        else:\n",
    "                            class_name = loaded_le.classes_[y_idx]\n",
    "                        \n",
    "                    else: # kps_stacked and kps_seq\n",
    "                        kps_seq.append(pose_row)\n",
    "                        if len(kps_seq) == SEQ_LEN:\n",
    "                            if MODEL_TYPE == 'kps_stacked':\n",
    "                                seq_arr = np.array(kps_seq).flatten()\n",
    "                            elif MODEL_TYPE == 'kps_seq':\n",
    "                                seq_arr = np.array(kps_seq)\n",
    "                            y_hat = loaded_model.predict(tf.expand_dims(seq_arr, axis=0))[0]\n",
    "                            y_idx = np.argmax(y_hat)\n",
    "\n",
    "                            if POST == 'hard_vote':\n",
    "                                # do hard voting\n",
    "                                preds_window.append(y_idx)\n",
    "                                pred_count = Counter(preds_window)\n",
    "                                # most_common return .items() format\n",
    "                                # ex. [(0,5), (1,3)]\n",
    "                                voted_pred = pred_count.most_common(1)[0][0]\n",
    "                                class_name = loaded_le.classes_[voted_pred]\n",
    "                            else:\n",
    "                                class_name = loaded_le.classes_[y_idx]\n",
    "                        else:\n",
    "                            class_name = \"None\"\n",
    "\n",
    "                    # count the rep logic\n",
    "                    current_stage = class_name\n",
    "\n",
    "                    if current_stage == COUNTING_ORDER[exercise]['cur_class'] and previous_stage == COUNTING_ORDER[exercise]['prev_class']:\n",
    "                        rep_count += 1\n",
    "\n",
    "                    previous_stage = current_stage  \n",
    "                except Exception as e:\n",
    "                    print(f'[INFO] error when {exercise}:', e)\n",
    "            # after 1 vid end\n",
    "            cap.release()\n",
    "            \n",
    "    else: # video_sequence, ViViT, image_single, Swin\n",
    "        vid_seq = deque(maxlen=SEQ_LEN)\n",
    "        current_stage = None\n",
    "        previous_stage = None\n",
    "        if POST == 'hard_vote':\n",
    "            preds_window = deque(maxlen=WINDOW_SIZE)\n",
    "        cap = cv2.VideoCapture(os.path.join(VID_DIR, exercise, file_name))\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            image_input = cv2.resize(frame, (120, 120))\n",
    "\n",
    "            if MODEL_TYPE in ['image_single', 'Swin']:\n",
    "                y_hat = loaded_model.predict(tf.expand_dims(image_input, axis=0))[0]\n",
    "                y_idx = np.argmax(y_hat)\n",
    "\n",
    "                if POST == 'hard_vote':\n",
    "                    # do hard voting\n",
    "                    preds_window.append(y_idx)\n",
    "                    pred_count = Counter(preds_window)\n",
    "                    # most_common return .items() format\n",
    "                    # ex. [(0,5), (1,3)]\n",
    "                    voted_pred = pred_count.most_common(1)[0][0]\n",
    "                    class_name = loaded_le.classes_[voted_pred]\n",
    "                else:\n",
    "                    class_name = loaded_le.classes_[y_idx]\n",
    "                    \n",
    "            else: # video_seqeunce, ViViT\n",
    "                vid_seq.append(image_input)\n",
    "\n",
    "                if len(vid_seq) == SEQ_LEN:\n",
    "                    input_seq = np.array(vid_seq) / 255.0\n",
    "                    y_hat = loaded_model.predict(tf.expand_dims(input_seq, axis=0))[0]\n",
    "                    y_idx = np.argmax(y_hat)\n",
    "\n",
    "                    if POST == 'hard_vote':\n",
    "                        # do hard voting\n",
    "                        preds_window.append(y_idx)\n",
    "                        pred_count = Counter(preds_window)\n",
    "                        # most_common return .items() format\n",
    "                        # ex. [(0,5), (1,3)]\n",
    "                        voted_pred = pred_count.most_common(1)[0][0]\n",
    "                        class_name = loaded_le.classes_[voted_pred]\n",
    "                    else:\n",
    "                        class_name = loaded_le.classes_[y_idx]\n",
    "                else:\n",
    "                    class_name = \"None\"\n",
    "\n",
    "            # count the rep logic\n",
    "            current_stage = class_name\n",
    "\n",
    "            if current_stage == COUNTING_ORDER[exercise]['cur_class'] and previous_stage == COUNTING_ORDER[exercise]['prev_class']:\n",
    "                rep_count += 1\n",
    "\n",
    "            previous_stage = current_stage\n",
    "    \n",
    "    print(f'{file_name}: {rep_count} from {rep_gt}')\n",
    "    obo_score = OBO(rep_count, rep_gt)\n",
    "    all_reps.append(rep_count)\n",
    "    all_obos.append(obo_score)\n",
    "    prev_ex = cur_ex\n",
    "    \n",
    "df['pred'] = all_reps\n",
    "df['obo'] = all_obos\n",
    "ds_name = DS_BASE_DIR.split(os.path.sep)[-1]\n",
    "df.to_csv(os.path.join(OUT_DIR, f'{MODEL_TYPE}_{POST}_{ds_name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "707f0525-8d35-47d7-822d-480297bca3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['pred', 'obo'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "200ead9f-3708-4c6f-bc3b-438c89baff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>rep</th>\n",
       "      <th>exercise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>half-burpee_1_1.mp4</td>\n",
       "      <td>11</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-burpee_1_2.mp4</td>\n",
       "      <td>9</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-burpee_2_1.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>half-burpee_2_2.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-burpee_2_3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>half-burpee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>squat_3_1.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>squat_3_2.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>squat_3_3.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>squat_3_4.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>squat_3_5.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>squat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name  rep     exercise\n",
       "0   half-burpee_1_1.mp4   11  half-burpee\n",
       "1   half-burpee_1_2.mp4    9  half-burpee\n",
       "2   half-burpee_2_1.mp4    3  half-burpee\n",
       "3   half-burpee_2_2.mp4    4  half-burpee\n",
       "4   half-burpee_2_3.mp4    3  half-burpee\n",
       "..                  ...  ...          ...\n",
       "63        squat_3_1.mp4    8        squat\n",
       "64        squat_3_2.mp4    6        squat\n",
       "65        squat_3_3.mp4    7        squat\n",
       "66        squat_3_4.mp4    5        squat\n",
       "67        squat_3_5.mp4    5        squat\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b758b3c-8766-4138-81d8-5afca348186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE\n",
    "# all squat fail from front view (some pushup too)\n",
    "\n",
    "# half-rep or worse exercise sample\n",
    "# pushup-6 | pushup-13 | \n",
    "\n",
    "# jumping-jack fail from multi person and completely sideview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezfit_tf2",
   "language": "python",
   "name": "ezfit_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
