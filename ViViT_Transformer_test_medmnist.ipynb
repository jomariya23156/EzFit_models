{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431f7782",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18251bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:44.241210Z",
     "start_time": "2022-01-24T14:01:32.750240Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "import medmnist\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 42\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b28d9",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3e880a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:55:56.413773Z",
     "start_time": "2022-01-24T14:55:56.400761Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "DATASET_NAME = 'organmnist3d'\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (28, 28, 28, 1)\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (8, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123eb81",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f9c091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:44.287212Z",
     "start_time": "2022-01-24T14:01:44.275213Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for downloading the dataset\n",
    "def download_and_prepare_dataset(data_info: dict):\n",
    "    data_path = keras.utils.get_file(origin=data_info['url'], md5_hash=data_info['MD5'])\n",
    "    \n",
    "    with np.load(data_path) as data:\n",
    "        # Get videos\n",
    "        train_videos = data['train_images']\n",
    "        valid_videos = data['val_images']\n",
    "        test_videos = data['test_images']\n",
    "        \n",
    "        # Get labels\n",
    "        train_labels = data['train_labels'].flatten()\n",
    "        valid_labels = data['val_labels'].flatten()\n",
    "        test_labels = data['test_labels'].flatten()\n",
    "        \n",
    "    return (\n",
    "    (train_videos, train_labels),\n",
    "    (valid_videos, valid_labels),\n",
    "    (test_videos, test_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03012737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:55:59.139428Z",
     "start_time": "2022-01-24T14:55:58.704430Z"
    }
   },
   "outputs": [],
   "source": [
    "# get meta data of the dataset\n",
    "info = medmnist.INFO[DATASET_NAME]\n",
    "\n",
    "# get the dataset\n",
    "prepared_dataset = download_and_prepare_dataset(info)\n",
    "(train_videos, train_labels) = prepared_dataset[0]\n",
    "(valid_videos, valid_labels) = prepared_dataset[1]\n",
    "(test_videos, test_labels) = prepared_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25db178",
   "metadata": {},
   "source": [
    "# tf.data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192461bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:44.303212Z",
     "start_time": "2022-01-24T14:01:44.290214Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    # preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "    frames[\n",
    "        ..., tf.newaxis\n",
    "    ],\n",
    "    tf.float32\n",
    "    )\n",
    "    # parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = 'train',\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "    \n",
    "    if loader_type == 'train':\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "    \n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208fe06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:56:01.133041Z",
     "start_time": "2022-01-24T14:56:00.987547Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = prepare_dataloader(train_videos, train_labels, 'train')\n",
    "validloader = prepare_dataloader(valid_videos, valid_labels, 'valid')\n",
    "testloader = prepare_dataloader(test_videos, test_labels, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d4694",
   "metadata": {},
   "source": [
    "# Tubelet Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2842df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:44.319212Z",
     "start_time": "2022-01-24T14:01:44.305213Z"
    }
   },
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding='VALID'\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "        \n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'patch_size': self.patch_size,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebf0be",
   "metadata": {},
   "source": [
    "# Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1378d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:44.427212Z",
     "start_time": "2022-01-24T14:01:44.410211Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "        \n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c56801",
   "metadata": {},
   "source": [
    "# ViViT Transformer\n",
    "implementing **Spatio-temporal attention** variant of this transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0f9ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:48.902241Z",
     "start_time": "2022-01-24T14:01:48.889211Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "    \n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential([\n",
    "            layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "            layers.Dense(units=embed_dim, activation=tf.nn.gelu)\n",
    "        ])(x3)\n",
    "        \n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "        \n",
    "    # Layer normalization and Global average pooling\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "    \n",
    "    # classify outputs\n",
    "    outputs = layers.Dense(units=num_classes, activation='softmax')(representation)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0193d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0f1168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:01:49.643215Z",
     "start_time": "2022-01-24T14:01:49.625213Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    # initializa model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "        embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM)\n",
    "    )\n",
    "    \n",
    "    # compile the model with the optimizer, loss function and the metrics\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name='top-5-accuracy')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # train the model\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
    "    \n",
    "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
    "    print(f'Test accuracy: {round(accuracy*100, 2)}%')\n",
    "    print(f'Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc15b719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T18:21:06.408273Z",
     "start_time": "2022-01-22T18:14:11.115213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "31/31 [==============================] - 15s 246ms/step - loss: 2.4100 - accuracy: 0.1307 - top-5-accuracy: 0.6111 - val_loss: 2.2180 - val_accuracy: 0.2422 - val_top-5-accuracy: 0.7081\n",
      "Epoch 2/60\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 2.0878 - accuracy: 0.2058 - top-5-accuracy: 0.7531 - val_loss: 1.9416 - val_accuracy: 0.2298 - val_top-5-accuracy: 0.7391\n",
      "Epoch 3/60\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 1.9232 - accuracy: 0.2500 - top-5-accuracy: 0.8282 - val_loss: 1.7017 - val_accuracy: 0.3168 - val_top-5-accuracy: 0.8696\n",
      "Epoch 4/60\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 1.7617 - accuracy: 0.2932 - top-5-accuracy: 0.8786 - val_loss: 1.5232 - val_accuracy: 0.3416 - val_top-5-accuracy: 0.9379\n",
      "Epoch 5/60\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 1.6091 - accuracy: 0.3467 - top-5-accuracy: 0.9043 - val_loss: 1.4992 - val_accuracy: 0.3168 - val_top-5-accuracy: 0.9503\n",
      "Epoch 6/60\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 1.4432 - accuracy: 0.4393 - top-5-accuracy: 0.9239 - val_loss: 1.2170 - val_accuracy: 0.4720 - val_top-5-accuracy: 0.9565\n",
      "Epoch 7/60\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 1.3383 - accuracy: 0.4805 - top-5-accuracy: 0.9414 - val_loss: 1.1929 - val_accuracy: 0.4969 - val_top-5-accuracy: 0.9752\n",
      "Epoch 8/60\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 1.3102 - accuracy: 0.4722 - top-5-accuracy: 0.9465 - val_loss: 1.0678 - val_accuracy: 0.5652 - val_top-5-accuracy: 0.9752\n",
      "Epoch 9/60\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 1.2364 - accuracy: 0.5185 - top-5-accuracy: 0.9496 - val_loss: 0.9949 - val_accuracy: 0.5714 - val_top-5-accuracy: 0.9814\n",
      "Epoch 10/60\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 1.2058 - accuracy: 0.5278 - top-5-accuracy: 0.9527 - val_loss: 0.8689 - val_accuracy: 0.6832 - val_top-5-accuracy: 0.9876\n",
      "Epoch 11/60\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 1.0700 - accuracy: 0.5813 - top-5-accuracy: 0.9619 - val_loss: 0.7665 - val_accuracy: 0.7391 - val_top-5-accuracy: 0.9938\n",
      "Epoch 12/60\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.9877 - accuracy: 0.6183 - top-5-accuracy: 0.9691 - val_loss: 0.7561 - val_accuracy: 0.6708 - val_top-5-accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.9471 - accuracy: 0.6440 - top-5-accuracy: 0.9784 - val_loss: 0.8702 - val_accuracy: 0.6832 - val_top-5-accuracy: 0.9752\n",
      "Epoch 14/60\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.9140 - accuracy: 0.6348 - top-5-accuracy: 0.9815 - val_loss: 0.7462 - val_accuracy: 0.7329 - val_top-5-accuracy: 0.9938\n",
      "Epoch 15/60\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.8060 - accuracy: 0.6903 - top-5-accuracy: 0.9846 - val_loss: 0.6560 - val_accuracy: 0.7453 - val_top-5-accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.7669 - accuracy: 0.7315 - top-5-accuracy: 0.9856 - val_loss: 0.4809 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9938\n",
      "Epoch 17/60\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.6272 - accuracy: 0.7840 - top-5-accuracy: 0.9897 - val_loss: 0.5235 - val_accuracy: 0.8199 - val_top-5-accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.5904 - accuracy: 0.8076 - top-5-accuracy: 0.9938 - val_loss: 0.5101 - val_accuracy: 0.8385 - val_top-5-accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.5864 - accuracy: 0.7778 - top-5-accuracy: 0.9959 - val_loss: 0.5114 - val_accuracy: 0.8261 - val_top-5-accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.6273 - accuracy: 0.7819 - top-5-accuracy: 0.9846 - val_loss: 0.5055 - val_accuracy: 0.8509 - val_top-5-accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.4806 - accuracy: 0.8374 - top-5-accuracy: 0.9918 - val_loss: 0.3943 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938\n",
      "Epoch 22/60\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.3801 - accuracy: 0.8704 - top-5-accuracy: 0.9959 - val_loss: 0.4661 - val_accuracy: 0.8634 - val_top-5-accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.3685 - accuracy: 0.8693 - top-5-accuracy: 0.9979 - val_loss: 0.3805 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.3833 - accuracy: 0.8611 - top-5-accuracy: 0.9990 - val_loss: 0.3610 - val_accuracy: 0.8634 - val_top-5-accuracy: 0.9938\n",
      "Epoch 25/60\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.3050 - accuracy: 0.8981 - top-5-accuracy: 0.9990 - val_loss: 0.4150 - val_accuracy: 0.9006 - val_top-5-accuracy: 0.9938\n",
      "Epoch 26/60\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.2785 - accuracy: 0.9023 - top-5-accuracy: 0.9979 - val_loss: 0.3222 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.2503 - accuracy: 0.9105 - top-5-accuracy: 0.9990 - val_loss: 0.2723 - val_accuracy: 0.9255 - val_top-5-accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.2369 - accuracy: 0.9228 - top-5-accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9130 - val_top-5-accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.2280 - accuracy: 0.9249 - top-5-accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.1884 - accuracy: 0.9331 - top-5-accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9193 - val_top-5-accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.1570 - accuracy: 0.9568 - top-5-accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.1643 - accuracy: 0.9506 - top-5-accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.1391 - accuracy: 0.9496 - top-5-accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9130 - val_top-5-accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0993 - accuracy: 0.9753 - top-5-accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.1142 - accuracy: 0.9599 - top-5-accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0779 - accuracy: 0.9774 - top-5-accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0608 - accuracy: 0.9815 - top-5-accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0502 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9193 - val_top-5-accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0371 - accuracy: 0.9938 - top-5-accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9379 - val_top-5-accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0347 - accuracy: 0.9918 - top-5-accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9938\n",
      "Epoch 41/60\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.1289 - accuracy: 0.9537 - top-5-accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8820 - val_top-5-accuracy: 0.9938\n",
      "Epoch 42/60\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.1366 - accuracy: 0.9588 - top-5-accuracy: 0.9990 - val_loss: 0.4709 - val_accuracy: 0.8820 - val_top-5-accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0691 - accuracy: 0.9835 - top-5-accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9255 - val_top-5-accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0305 - accuracy: 0.9949 - top-5-accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.8758 - val_top-5-accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0331 - accuracy: 0.9928 - top-5-accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0378 - accuracy: 0.9897 - top-5-accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0290 - accuracy: 0.9949 - top-5-accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0116 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9193 - val_top-5-accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0060 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0042 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0031 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9379 - val_top-5-accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0030 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9255 - val_top-5-accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0026 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9441 - val_top-5-accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0022 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9379 - val_top-5-accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0018 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0018 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0014 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9317 - val_top-5-accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0014 - accuracy: 1.0000 - top-5-accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9379 - val_top-5-accuracy: 1.0000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.9532 - accuracy: 0.8049 - top-5-accuracy: 0.9820\n",
      "Test accuracy: 80.49%\n",
      "Test top 5 accuracy: 98.2%\n"
     ]
    }
   ],
   "source": [
    "model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ce0b468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-22T18:21:06.764307Z",
     "start_time": "2022-01-22T18:21:06.411274Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\transformers-dl\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/test_ViViT.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6589ea77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:05:22.431252Z",
     "start_time": "2022-01-24T14:05:22.420250Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3a7e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:54:44.928630Z",
     "start_time": "2022-01-24T14:54:43.112632Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('saved_models/test_ViViT.h5', custom_objects={\"TubeletEmbedding\": TubeletEmbedding, \n",
    "                                                                        \"PositionalEncoder\": PositionalEncoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "580b90a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:54:50.435070Z",
     "start_time": "2022-01-24T14:54:50.396070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 28,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tubelet_embedding (TubeletEmbe  (None, 27, 128)     65664       ['input_1[0][0]']                \n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " positional_encoder (Positional  (None, 27, 128)     3456        ['tubelet_embedding[0][0]']      \n",
      " Encoder)                                                                                         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 27, 128)     256         ['positional_encoder[0][0]']     \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 27, 128)     66048       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 27, 128)      0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'positional_encoder[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 27, 128)     256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 27, 128)      131712      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 27, 128)      0           ['sequential[0][0]',             \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 27, 128)     256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 27, 128)     66048       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 27, 128)      0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 27, 128)     256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 27, 128)      0           ['sequential_1[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 27, 128)     256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 27, 128)     66048       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 27, 128)      0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 27, 128)     256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 27, 128)      0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 27, 128)     256         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 27, 128)     66048       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 27, 128)      0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 27, 128)     256         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 27, 128)      0           ['sequential_3[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 27, 128)     256         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 27, 128)     66048       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 27, 128)      0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 27, 128)     256         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 27, 128)      0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 27, 128)     256         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 27, 128)     66048       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 27, 128)      0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 27, 128)     256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 27, 128)      0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 27, 128)     256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 27, 128)     66048       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 27, 128)      0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 27, 128)     256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 27, 128)      0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 27, 128)     256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 27, 128)     66048       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 27, 128)      0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 27, 128)     256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 27, 128)      131712      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 27, 128)      0           ['sequential_7[0][0]',           \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 27, 128)     256         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_16[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 11)           1419        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,656,971\n",
      "Trainable params: 1,656,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098022d1",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e5cc37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T14:56:10.709096Z",
     "start_time": "2022-01-24T14:56:05.260738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5c4f3b6b174cebb7fd5e2e3c3fb375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(VBox(children=(HTML(value=\"'T: pancreas | P: pancreas'\"), Box(children=(Image(value=b'GIF89a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SAMPLES_VIZ = 25\n",
    "testsamples, labels = next(iter(testloader))\n",
    "testsamples, labels = testsamples[:NUM_SAMPLES_VIZ], labels[:NUM_SAMPLES_VIZ]\n",
    "\n",
    "ground_truths = []\n",
    "preds = []\n",
    "videos = []\n",
    "\n",
    "for i, (testsample, label) in enumerate(zip(testsamples, labels)):\n",
    "    # Generate gif\n",
    "    with io.BytesIO() as gif:\n",
    "        imageio.mimsave(gif, (testsample.numpy() * 255).astype('uint8'), 'GIF', fps=5)\n",
    "        videos.append(gif.getvalue())\n",
    "    \n",
    "    # get prediction\n",
    "    output = loaded_model.predict(tf.expand_dims(testsample, axis=0))[0]\n",
    "    pred = np.argmax(output, axis=0)\n",
    "    \n",
    "    ground_truths.append(label.numpy().astype('int'))\n",
    "    preds.append(pred)\n",
    "    \n",
    "def make_box_for_grid(image_widget, fit):\n",
    "    '''\n",
    "    Make a VBox to hold caption/image for demonstrating optino_fit values.\n",
    "    \n",
    "    Source: https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Styling.html\n",
    "    '''\n",
    "    # Make the caption\n",
    "    if fit is not None:\n",
    "        fit_str = f\"'{fit}'\"\n",
    "    else:\n",
    "        fit_str = str(fit)\n",
    "        \n",
    "    h = ipywidgets.HTML(value='' + str(fit_str) + '')\n",
    "    \n",
    "    # make the green box with the image widget inside it\n",
    "    boxb = ipywidgets.widgets.Box()\n",
    "    boxb.children = [image_widget]\n",
    "    \n",
    "    # Compose into a vertical box\n",
    "    vb = ipywidgets.widgets.VBox()\n",
    "    vb.layout.align_items = 'center'\n",
    "    vb.children = [h, boxb]\n",
    "    return vb\n",
    "\n",
    "boxes = []\n",
    "for i in range(NUM_SAMPLES_VIZ):\n",
    "    ib = ipywidgets.widgets.Image(value=videos[i], width=100, height=100)\n",
    "    true_class = info['label'][str(ground_truths[i])]\n",
    "    pred_class = info['label'][str(preds[i])]\n",
    "    caption = f'T: {true_class} | P: {pred_class}'\n",
    "    \n",
    "    boxes.append(make_box_for_grid(ib, caption))\n",
    "    \n",
    "ipywidgets.widgets.GridBox(\n",
    "    boxes, layout=ipywidgets.widgets.Layout(grid_template_columns='repeat(5, 200px)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a14742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-dl",
   "language": "python",
   "name": "transformers-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
